{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": ".venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "extract_additional_financial_metrics.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YB7c8CNAgLT",
        "outputId": "7dd7100d-bce2-47e1-c146-618f40e81776"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv1D, MaxPool1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
        "from tensorflow.keras import models\n",
        "from keras.models import load_model\n",
        "print(tf.__version__)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, recall_score, classification_report,precision_score,f1_score, plot_confusion_matrix\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import  seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.metrics import classification_report_imbalanced"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "_qdZHldPAgLW",
        "outputId": "9347a0b5-d531-4669-ec69-b93fb8b50eed"
      },
      "source": [
        "classifier = ['extra_trees_on_', 'logistic_regression_on_','normal_model_cnn_on_','normal_model_fcn_on_','random_forest_on_', 'transfer_model_cnn_on_', 'transfer_model_fcn_on_']\n",
        "samples= ['ADASYN_samples','BorderlineSmote_samples', 'CSMOUTE_samples', 'MWMOTE_samples','SMOTEENN_samples','SMOTE_samples']\n",
        "\n",
        "\n",
        "for i in classifier:\n",
        "  for j in samples:\n",
        "    csv_link= '.csv'\n",
        "    sample=str(i+j+csv_link)\n",
        "    classifier= pd.read_csv(sample)\n",
        "\n",
        "    cm= confusion_matrix(classifier['is_fraud'], classifier['is_fraud.1'])\n",
        "    cm= pd.DataFrame(cm)\n",
        "    cm_csv= '_cm.csv'\n",
        "    cm_to_csv= i+j+cm_csv\n",
        "    cm.to_csv(cm_to_csv)\n",
        "\n",
        "    false_negatives= np.logical_and(classifier['is_fraud'] != classifier['is_fraud.1'], classifier['is_fraud.1']==0)\n",
        "    false_positives= np.logical_and(classifier['is_fraud']!=classifier['is_fraud.1'], classifier['is_fraud.1']== 1)\n",
        "    credit_fraud_data_fp= test[false_positives==True]\n",
        "    credit_fraud_data_fn= test[false_negatives==True]\n",
        "\n",
        "    loss_with_classifier_value= np.sum(credit_fraud_data_fn['amt'])\n",
        "    loss_with_classifier= pd.DataFrame(['Total loss when using this classifier: ', loss_with_classifier_value])\n",
        "    print(loss_with_classifier_value)\n",
        "\n",
        "    extract_fraud= test[test['is_fraud']==1]\n",
        "    loss_without_classifier_value=  np.sum(extract_fraud['amt'])\n",
        "    loss_without_classifier= pd.DataFrame(['Total loss without using this classifier: ', loss_without_classifier_value])\n",
        "\n",
        "    savings_with_classifier_value=loss_without_classifier_value-loss_with_classifier_value\n",
        "    savings_with_classifier= pd.DataFrame(['Money saved when using this classifier: ', savings_with_classifier_value])\n",
        "\n",
        "    financial_loss_general_value= (np.average(credit_fraud_data_fp['amt'])*len(credit_fraud_data_fp))+(np.average(credit_fraud_data_fn['amt'])*len(credit_fraud_data_fn))\n",
        "    financial_loss_general = pd.DataFrame(['Financial Loss (avg cost: missed fraud)*(FN) + (avg cost: investigating fraud)*(FP)', financial_loss_general_value])\n",
        "\n",
        "    class_report= classification_report_imbalanced(classifier['is_fraud'],classifier['is_fraud.1'])\n",
        "    print(class_report)\n",
        "    class_report_imb_csv = pd.read_csv(StringIO(re.sub(r'[-+|]', '', class_report)), sep='\\s{2,}', engine='python')\n",
        "    report_to_csv= '_class_report_imb.csv'\n",
        "    cri_csv= i+j+report_to_csv\n",
        "    class_report_imb_csv.to_csv(cri_csv)\n",
        "\n",
        "    with open(cri_csv,'a') as f:\n",
        "      loss_with_classifier.to_csv(f, header=False, sep=',')\n",
        "      loss_without_classifier.to_csv(f, header=False, sep=',')\n",
        "      savings_with_classifier.to_csv(f, header=False, sep=',')\n",
        "      financial_loss_general.to_csv(f, header=False, sep=',')\n",
        "  \n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-dc056d4ef357>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcsv_link\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcsv_link\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mcm\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_fraud'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_fraud.1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXrcpiwr96Xg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}